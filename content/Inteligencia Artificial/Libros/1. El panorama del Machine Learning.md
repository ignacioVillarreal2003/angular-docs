---
title: El panorama del Machine Learning
subtitle: Explora los conceptos fundamentales del Machine Learning, desde sus tipos de aprendizaje hasta los desafíos clave en su implementación.
order: 1
date: 24/09/2025
coverImage: cover-image-1.png
---

Cuando la mayoría de las personas escucha “Machine Learning”, imagina un robot: un mayordomo confiable o un letal Terminator, según a quién le preguntes. Pero el Machine Learning no es solo una fantasía futurista, ya está aquí. De hecho, ha existido durante décadas en algunas aplicaciones especializadas, como el reconocimiento óptico de caracteres (Optical Character Recognition, OCR). Pero la primera aplicación de ML que realmente se volvió masiva, mejorando la vida de cientos de millones de personas, conquistó el mundo en la década de 1990: fue el filtro de spam. No es exactamente una Skynet autoconsciente, pero técnicamente califica como Machine Learning (en realidad ha aprendido tan bien que rara vez necesitás marcar un correo como spam hoy en día). Luego le siguieron cientos de aplicaciones de ML que ahora impulsan silenciosamente cientos de productos y funciones que usás habitualmente, desde mejores recomendaciones hasta búsqueda por voz.

¿Dónde empieza y dónde termina el Machine Learning? ¿Qué significa exactamente que una máquina aprenda algo? Si descargo una copia de Wikipedia, ¿mi computadora realmente ha “aprendido” algo? ¿Es repentinamente más inteligente? En este capítulo comenzaremos aclarando qué es el Machine Learning y por qué podrías querer usarlo.

Luego, antes de disponernos a explorar el continente del Machine Learning, echaremos un vistazo al mapa y conoceremos las principales regiones y los hitos más notables: aprendizaje supervisado versus no supervisado, aprendizaje en línea versus por lotes, aprendizaje basado en instancias versus basado en modelos. Después veremos el flujo de trabajo de un proyecto típico de ML, hablaremos de los principales desafíos que podés enfrentar y cubriremos cómo evaluar y ajustar un sistema de Machine Learning.

> Este capítulo presenta muchos conceptos fundamentales (y jerga) que todo científico de datos debería saber de memoria. Será una visión general de alto nivel (el único capítulo sin mucho código), todo bastante simple, pero deberías asegurarte de que todo te quede perfectamente claro antes de continuar con el resto del libro. Así que agarrá un café y ¡empecemos!

# ¿Qué es Machine Learning?

El Machine Learning es la ciencia (y el arte) de programar computadoras para que puedan aprender a partir de datos.

Aquí hay una definición un poco más general:

    [Machine Learning es el] campo de estudio que da a las computadoras la capacidad de aprender sin ser explícitamente programadas.  
    
    —Arthur Samuel, 1959

Y una más orientada a la ingeniería:

    Se dice que un programa de computadora aprende de la experiencia E con respecto a alguna tarea T y alguna medida de rendimiento P, si su rendimiento en T, medido por P, mejora con la experiencia E.  
    
    —Tom Mitchell, 1997

Por ejemplo, tu filtro de spam es un programa de Machine Learning que puede aprender a marcar spam dado ejemplos de correos electrónicos de spam (por ejemplo, marcados por los usuarios) y ejemplos de correos regulares (no spam, también llamados “ham”). Los ejemplos que el sistema utiliza para aprender se llaman conjunto de entrenamiento (training set). Cada ejemplo de entrenamiento se llama instancia de entrenamiento (o muestra). En este caso, la tarea T es marcar el spam en nuevos correos, la experiencia E son los datos de entrenamiento, y la medida de rendimiento P debe definirse; por ejemplo, podés usar la proporción de correos clasificados correctamente. Esta medida de rendimiento en particular se llama precisión (accuracy) y se usa a menudo en tareas de clasificación.

Si simplemente descargás una copia de Wikipedia, tu computadora tiene muchos más datos, pero no es repentinamente mejor en ninguna tarea. Por lo tanto, eso no es Machine Learning.

# ¿Por qué usar Machine Learning?

Considerá cómo escribirías un filtro de spam usando técnicas de programación tradicionales (Figura 1-1):

1. Primero analizarías cómo suele verse el spam. Podrías notar que algunas palabras o frases (como “4U”, “credit card”, “free” y “amazing”) tienden a aparecer mucho en el asunto. Quizás también notarías algunos otros patrones en el nombre del remitente, el cuerpo del correo, etc.  
2. Escribirías un algoritmo de detección para cada uno de los patrones que observaste, y tu programa marcaría los correos como spam si detecta varios de estos patrones.  
3. Probarías tu programa y repetirías los pasos 1 y 2 hasta que fuera lo suficientemente bueno.

[[img:1.0.png]]
Figura 1-1. El enfoque tradicional
[[/img]]

Dado que el problema no es trivial, tu programa probablemente se convertiría en una larga lista de reglas complejas, bastante difíciles de mantener.

En cambio, un filtro de spam basado en técnicas de Machine Learning aprende automáticamente qué palabras y frases son buenos predictores de spam al detectar patrones de palabras inusualmente frecuentes en los ejemplos de spam en comparación con los ejemplos de ham (Figura 1-2). El programa es mucho más corto, más fácil de mantener y, con toda probabilidad, más preciso.

[[img:1.1.png]]
Figura 1-2. Enfoque de Machine Learning
[[/img]]

Además, si los spammers notan que todos sus correos que contienen “4U” son bloqueados, podrían empezar a escribir “For U” en su lugar. Un filtro de spam con programación tradicional tendría que actualizarse para marcar también los correos con “For U”. Si los spammers siguen encontrando maneras de esquivar tu filtro, tendrás que seguir escribiendo nuevas reglas indefinidamente.

En cambio, un filtro basado en Machine Learning nota automáticamente que “For U” se ha vuelto inusualmente frecuente en el spam marcado por los usuarios, y empieza a marcarlo sin tu intervención (Figura 1-3).

[[img:1.2.png]]
Figura 1-3. Adaptación automática al cambio
[[/img]]

Otra área donde el Machine Learning sobresale es en problemas que son demasiado complejos para los enfoques tradicionales o que no tienen un algoritmo conocido. Por ejemplo, considerá el reconocimiento de voz: supongamos que querés empezar de forma simple y escribir un programa capaz de distinguir las palabras “one” y “two”. Podrías notar que la palabra “two” comienza con un sonido agudo (“T”), por lo que podrías programar un algoritmo que mida la intensidad de sonidos agudos y usarlo para distinguir entre “one” y “two”. Obviamente, esta técnica no escalará a miles de palabras pronunciadas por millones de personas muy diferentes, en entornos ruidosos y en docenas de idiomas. La mejor solución (al menos hoy en día) es escribir un algoritmo que aprenda por sí mismo, dadas muchas grabaciones de ejemplo para cada palabra.

Finalmente, el Machine Learning puede ayudar a los humanos a aprender (Figura 1-4): los algoritmos de ML pueden inspeccionarse para ver qué han aprendido (aunque para algunos algoritmos esto puede ser complicado). Por ejemplo, una vez que el filtro de spam ha sido entrenado con suficiente spam, puede inspeccionarse fácilmente para revelar la lista de palabras y combinaciones de palabras que considera los mejores predictores de spam. A veces esto revelará correlaciones inesperadas o nuevas tendencias, lo que puede conducir a una mejor comprensión del problema. Aplicar técnicas de ML para explorar grandes cantidades de datos puede ayudar a descubrir patrones que no eran evidentes de inmediato. Esto se llama minería de datos (data mining).

[[img:1.3.png]]
Figura 1-4. El Machine Learning puede ayudar a los humanos a aprender
[[/img]]

En resumen, el Machine Learning es excelente para:

* Problemas cuyas soluciones existentes requieren mucho ajuste manual o largas listas de reglas: un solo algoritmo de Machine Learning puede simplificar el código y rendir mejor.  
* Problemas complejos para los que no existe una buena solución con un enfoque tradicional: las mejores técnicas de Machine Learning pueden encontrar una solución.  
* Entornos cambiantes: un sistema de Machine Learning puede adaptarse a nuevos datos.  
* Obtener información sobre problemas complejos y grandes cantidades de datos.

# Tipos de sistemas de Machine Learning

Existen tantos tipos diferentes de sistemas de Machine Learning que resulta útil clasificarlos en categorías generales basadas en:

* Si están o no entrenados con supervisión humana (aprendizaje supervisado, no supervisado, semisupervisado y Reinforcement Learning).  
* Si pueden o no aprender de manera incremental sobre la marcha (aprendizaje en línea versus por lotes).  
* Si funcionan simplemente comparando nuevos puntos de datos con puntos de datos conocidos, o si detectan patrones en los datos de entrenamiento y construyen un modelo predictivo, de forma similar a como lo hacen los científicos (aprendizaje basado en instancias versus basado en modelos).

Estos criterios no son excluyentes; podés combinarlos como quieras. Por ejemplo, un filtro de spam de última generación puede aprender sobre la marcha usando un modelo de red neuronal profunda entrenado con ejemplos de spam y ham; esto lo convierte en un sistema de aprendizaje supervisado, en línea y basado en modelos.

Veamos cada uno de estos criterios con un poco más de detalle.

## Aprendizaje supervisado / no supervisado

Los sistemas de Machine Learning pueden clasificarse según la cantidad y el tipo de supervisión que reciben durante el entrenamiento. Hay cuatro categorías principales: aprendizaje supervisado, aprendizaje no supervisado, aprendizaje semisupervisado y Reinforcement Learning.

### Aprendizaje supervisado

En el aprendizaje supervisado, los datos de entrenamiento que le das al algoritmo incluyen las soluciones deseadas, llamadas etiquetas (labels) (Figura 1-5).

[[img:1.4.png]]
Figura 1-5. Un conjunto de entrenamiento etiquetado para aprendizaje supervisado (por ejemplo, clasificación de spam)
[[/img]]

Una tarea típica de aprendizaje supervisado es la clasificación. El filtro de spam es un buen ejemplo: se entrena con muchos correos electrónicos de ejemplo junto con su clase (spam o ham), y debe aprender cómo clasificar nuevos correos.

Otra tarea típica es predecir un valor numérico objetivo, como el precio de un automóvil, dado un conjunto de características (kilometraje, antigüedad, marca, etc.) llamadas predictores. Este tipo de tarea se llama regresión (Figura 1-6). Para entrenar el sistema, debés darle muchos ejemplos de automóviles, incluyendo tanto sus predictores como sus etiquetas (es decir, sus precios).

> En Machine Learning, un atributo es un tipo de dato (por ejemplo, “Mileage”), mientras que una característica (feature) tiene varios significados según el contexto, pero generalmente significa un atributo más su valor (por ejemplo, “Mileage \= 15,000”). Muchas personas usan las palabras atributo y característica indistintamente.

[[img:1.5.png]]
Figura 1-6. Regresión
[[/img]]

Cabe destacar que algunos algoritmos de regresión también pueden usarse para clasificación, y viceversa. Por ejemplo, la regresión logística (Logistic Regression) se usa comúnmente para clasificación, ya que puede producir un valor que corresponde a la probabilidad de pertenecer a una clase dada (por ejemplo, un 20% de probabilidad de ser spam).

Algunos de los algoritmos de aprendizaje supervisado más importantes (cubiertos en este libro) son:

* k-Nearest Neighbors  
* Regresión lineal (Linear Regression)  
* Regresión logística (Logistic Regression)  
* Máquinas de soporte vectorial (Support Vector Machines, SVMs)  
* Árboles de decisión y bosques aleatorios (Decision Trees and Random Forests)  
* Redes neuronales (Neural networks)

### Aprendizaje no supervisado

En el aprendizaje no supervisado, como podrás suponer, los datos de entrenamiento no están etiquetados (Figura 1-7). El sistema intenta aprender sin un maestro.

[[img:1.6.png]]
Figura 1-7. Un conjunto de entrenamiento no etiquetado para aprendizaje no supervisado
[[/img]]

Algunos de los algoritmos de aprendizaje no supervisado más importantes (la mayoría se cubren en los capítulos 8 y 9\) son:

* Clustering  
   — K-Means  
   — DBSCAN  
   — Análisis de clúster jerárquico (Hierarchical Cluster Analysis, HCA)  
* Detección de anomalías y detección de novedades  
   — One-class SVM  
   — Isolation Forest  
* Visualización y reducción de dimensionalidad  
   — Análisis de componentes principales (Principal Component Analysis, PCA)  
   — Kernel PCA  
   — Embedding lineal local (Locally-Linear Embedding, LLE)  
   — t-distributed Stochastic Neighbor Embedding (t-SNE)  
* Aprendizaje de reglas de asociación  
   — Apriori  
   — Eclat

Por ejemplo, supongamos que tenés muchos datos sobre los visitantes de tu blog. Podrías ejecutar un algoritmo de clustering para tratar de detectar grupos de visitantes similares (Figura 1-8). En ningún momento le decís al algoritmo a qué grupo pertenece cada visitante: encuentra esas conexiones sin tu ayuda. Por ejemplo, podría notar que el 40% de tus visitantes son hombres que aman los cómics y que generalmente leen tu blog por la noche, mientras que el 20% son jóvenes aficionados a la ciencia ficción que lo visitan los fines de semana, y así sucesivamente. Si usás un algoritmo de clustering jerárquico, también podría subdividir cada grupo en grupos más pequeños. Esto puede ayudarte a orientar tus publicaciones para cada grupo.

[[img:1.7.png]]
Figura 1-8. Clustering
[[/img]]

Los algoritmos de visualización también son buenos ejemplos de aprendizaje no supervisado: les das una gran cantidad de datos complejos y no etiquetados, y producen una representación 2D o 3D de tus datos que puede graficarse fácilmente (Figura 1-9). Estos algoritmos intentan preservar la mayor cantidad de estructura posible (por ejemplo, tratar de mantener separados en la visualización los clústeres que están separados en el espacio de entrada), para que puedas comprender cómo están organizados los datos e incluso identificar patrones inesperados.

[[img:1.8.png]]
Figura 1-9. Ejemplo de visualización t-SNE que resalta clústeres semánticos
[[/img]]

Una tarea relacionada es la reducción de dimensionalidad, cuyo objetivo es simplificar los datos sin perder demasiada información. Una forma de hacer esto es combinar varias características correlacionadas en una sola. Por ejemplo, el kilometraje de un auto puede estar muy correlacionado con su antigüedad, por lo que el algoritmo de reducción de dimensionalidad los combinará en una característica que represente el desgaste del auto. A esto se le llama extracción de características (feature extraction).

> A menudo es una buena idea reducir la dimensión de tus datos de entrenamiento usando un algoritmo de reducción de dimensionalidad antes de dárselos a otro algoritmo de Machine Learning (como uno supervisado). Esto permitirá que se ejecute mucho más rápido, que los datos ocupen menos espacio en disco y memoria, y en algunos casos también puede mejorar el rendimiento.

Otra tarea importante del aprendizaje no supervisado es la detección de anomalías, por ejemplo, detectar transacciones inusuales con tarjeta de crédito para prevenir fraudes, detectar defectos de fabricación o eliminar automáticamente valores atípicos de un conjunto de datos antes de entregarlo a otro algoritmo de aprendizaje. El sistema recibe en entrenamiento principalmente instancias normales, por lo que aprende a reconocerlas y, cuando ve una nueva instancia, puede determinar si parece normal o si probablemente sea una anomalía (Figura 1-10). Una tarea muy similar es la detección de novedades: la diferencia es que los algoritmos de detección de novedades esperan ver solo datos normales durante el entrenamiento, mientras que los de detección de anomalías suelen ser más tolerantes y pueden funcionar bien incluso con un pequeño porcentaje de valores atípicos en el conjunto de entrenamiento.

[[img:1.9.png]]
Figura 1-10. Detección de anomalías
[[/img]]

Finalmente, otra tarea común de aprendizaje no supervisado es el aprendizaje de reglas de asociación, cuyo objetivo es analizar grandes volúmenes de datos y descubrir relaciones interesantes entre atributos. Por ejemplo, supongamos que tenés un supermercado. Ejecutar un algoritmo de reglas de asociación sobre tus registros de ventas podría revelar que las personas que compran salsa barbacoa y papas fritas también tienden a comprar carne para asar. En consecuencia, podrías querer colocar estos artículos cerca unos de otros.

### Aprendizaje semisupervisado

Algunos algoritmos pueden manejar datos de entrenamiento parcialmente etiquetados, generalmente con mucha cantidad de datos no etiquetados y una pequeña cantidad de datos etiquetados. Esto se llama aprendizaje semisupervisado (Figura 1-11).

Algunos servicios de alojamiento de fotos, como Google Photos, son buenos ejemplos de esto. Una vez que subís todas tus fotos familiares al servicio, este reconoce automáticamente que la misma persona A aparece en las fotos 1, 5 y 11, mientras que otra persona B aparece en las fotos 2, 5 y 7. Esta es la parte no supervisada del algoritmo (clustering). Ahora, todo lo que el sistema necesita es que le indiques quiénes son esas personas. Con solo una etiqueta por persona, es capaz de identificar a todos en cada foto, lo cual es útil para buscar imágenes.

[[img:1.10.png]]
Figura 1-11. Aprendizaje semisupervisado
[[/img]]

La mayoría de los algoritmos de aprendizaje semisupervisado son combinaciones de algoritmos no supervisados y supervisados. Por ejemplo, las redes de creencia profunda (deep belief networks, DBNs) se basan en componentes no supervisados llamados máquinas de Boltzmann restringidas (restricted Boltzmann machines, RBMs) apiladas una sobre otra. Las RBMs se entrenan secuencialmente de forma no supervisada y luego se ajusta todo el sistema usando técnicas de aprendizaje supervisado.

### Reinforcement Learning

El Reinforcement Learning es un caso muy diferente. El sistema de aprendizaje, llamado agente en este contexto, puede observar el entorno, seleccionar y ejecutar acciones, y recibir recompensas a cambio (o castigos en forma de recompensas negativas, como en la Figura 1-12). Luego debe aprender por sí mismo cuál es la mejor estrategia, llamada política (policy), para obtener la mayor recompensa a lo largo del tiempo. Una política define qué acción debe elegir el agente cuando se encuentra en una situación determinada.

[[img:1.11.png]]
Figura 1-12. Reinforcement Learning
[[/img]]

Por ejemplo, muchos robots implementan algoritmos de Reinforcement Learning para aprender a caminar. El programa AlphaGo de DeepMind es también un buen ejemplo de Reinforcement Learning: fue noticia en mayo de 2017 cuando venció al campeón mundial Ke Jie en el juego de Go. Aprendió su política ganadora analizando millones de partidas y luego jugando muchas partidas contra sí mismo. Cabe señalar que el aprendizaje se desactivó durante las partidas contra el campeón; AlphaGo simplemente estaba aplicando la política que había aprendido.

## Aprendizaje por Lotes y en Línea

Otro criterio utilizado para clasificar los sistemas de Machine Learning es si el sistema puede o no aprender de manera incremental a partir de un flujo de datos entrante.

### Aprendizaje por lotes

En el aprendizaje por lotes, el sistema es incapaz de aprender de forma incremental: debe ser entrenado utilizando todos los datos disponibles. Esto generalmente tomará mucho tiempo y recursos de cómputo, por lo que normalmente se realiza offline. Primero se entrena el sistema y luego se pone en producción y funciona sin seguir aprendiendo; simplemente aplica lo que ha aprendido. Esto se llama offline learning.

Si se quiere que un sistema de aprendizaje por lotes conozca nuevos datos (como un nuevo tipo de spam), se necesita entrenar una nueva versión del sistema desde cero con el conjunto completo de datos (no solo los datos nuevos, sino también los antiguos), luego detener el sistema anterior y reemplazarlo por el nuevo.

Afortunadamente, todo el proceso de entrenamiento, evaluación y despliegue de un sistema de Machine Learning puede automatizarse con bastante facilidad (como se muestra en la Figura 1-3), por lo que incluso un sistema de aprendizaje por lotes puede adaptarse a cambios. Simplemente se actualizan los datos y se entrena una nueva versión del sistema desde cero tantas veces como sea necesario.

Esta solución es simple y a menudo funciona bien, pero el entrenamiento usando el conjunto completo de datos puede tomar muchas horas, por lo que normalmente se entrena un nuevo sistema solo cada 24 horas o incluso semanalmente. Si el sistema necesita adaptarse a datos que cambian rápidamente (por ejemplo, para predecir precios de acciones), entonces se necesita una solución más reactiva.

Además, entrenar con el conjunto completo de datos requiere muchos recursos de cómputo (CPU, espacio de memoria, espacio en disco, I/O de disco, I/O de red, etc.). Si se tiene una gran cantidad de datos y se automatiza el sistema para que entrene desde cero todos los días, terminará costando mucho dinero. Si la cantidad de datos es enorme, puede que incluso sea imposible usar un algoritmo de aprendizaje por lotes.

Finalmente, si el sistema necesita ser capaz de aprender de forma autónoma y cuenta con recursos limitados (por ejemplo, una aplicación de smartphone o un rover en Marte), entonces transportar grandes cantidades de datos de entrenamiento y consumir muchos recursos para entrenar durante horas cada día es un obstáculo insalvable.

Afortunadamente, en todos estos casos, una mejor opción es usar algoritmos que sean capaces de aprender de forma incremental.

### Aprendizaje en línea

En el aprendizaje en línea, el sistema se entrena de forma incremental alimentándolo con instancias de datos de manera secuencial, ya sea individualmente o en pequeños grupos llamados mini-batches. Cada paso de aprendizaje es rápido y económico, por lo que el sistema puede aprender sobre nuevos datos en tiempo real, a medida que llegan (ver Figura 1-13).

[[img:1.12.png]]
Figura 1-13. Aprendizaje en línea
[[/img]]

El aprendizaje en línea es ideal para sistemas que reciben datos como un flujo continuo (por ejemplo, precios de acciones) y necesitan adaptarse rápidamente a los cambios o de forma autónoma. También es una buena opción si se tienen recursos de cómputo limitados: una vez que un sistema de aprendizaje en línea ha aprendido sobre nuevas instancias de datos, ya no las necesita, por lo que se pueden descartar (a menos que se quiera tener la capacidad de volver a un estado anterior y “reproducir” los datos). Esto puede ahorrar una enorme cantidad de espacio.  
Los algoritmos de aprendizaje en línea también pueden usarse para entrenar sistemas con conjuntos de datos enormes que no caben en la memoria principal de una sola máquina (esto se llama out-of-core learning). El algoritmo carga parte de los datos, ejecuta un paso de entrenamiento con esos datos y repite el proceso hasta que ha procesado todos los datos (ver Figura 1-14).

> El out-of-core learning normalmente se realiza offline (es decir, no en el sistema en vivo), por lo que el término online learning puede resultar confuso. Piense en él como aprendizaje incremental.

[[img:1.13.png]]
Figura 1-14. Uso del aprendizaje en línea para manejar conjuntos de datos enormes
[[/img]]

Un parámetro importante de los sistemas de aprendizaje en línea es la velocidad con la que deben adaptarse a datos cambiantes: esto se llama learning rate. Si se establece un learning rate alto, el sistema se adaptará rápidamente a los datos nuevos, pero también tenderá a olvidar rápidamente los datos antiguos (no se quiere que un filtro de spam solo marque los últimos tipos de spam que ha visto). Por el contrario, si se establece un learning rate bajo, el sistema tendrá más inercia; es decir, aprenderá más lentamente, pero también será menos sensible al ruido en los datos nuevos o a secuencias de puntos de datos no representativos (outliers).

Un gran desafío con el aprendizaje en línea es que, si se alimenta al sistema con datos erróneos, el rendimiento del sistema disminuirá gradualmente. Si hablamos de un sistema en vivo, sus clientes lo notarán. Por ejemplo, los datos erróneos podrían provenir de un sensor defectuoso en un robot o de alguien enviando spam a un motor de búsqueda para intentar posicionarse alto en los resultados. Para reducir este riesgo, es necesario monitorear el sistema de cerca y desactivar rápidamente el aprendizaje (y posiblemente volver a un estado funcional previo) si se detecta una caída en el rendimiento. También se puede querer monitorear los datos de entrada y reaccionar ante datos anormales (por ejemplo, usando un algoritmo de detección de anomalías).

## Aprendizaje Basado en Instancias versus Aprendizaje Basado en Modelos

Otra forma de categorizar los sistemas de Machine Learning es según cómo generalizan.

La mayoría de las tareas de Machine Learning tienen que ver con hacer predicciones. Esto significa que, dado un número de ejemplos de entrenamiento, el sistema debe ser capaz de generalizar a ejemplos que nunca ha visto antes. Tener una buena medida de rendimiento en los datos de entrenamiento es bueno, pero insuficiente; el verdadero objetivo es desempeñarse bien con nuevas instancias.

Hay dos enfoques principales para la generalización: aprendizaje basado en instancias y aprendizaje basado en modelos.

### Aprendizaje basado en instancias

Posiblemente, la forma más trivial de aprendizaje es simplemente aprender de memoria. Si crearas un filtro de spam de esta manera, simplemente marcaría todos los correos electrónicos que sean idénticos a correos que ya han sido marcados por los usuarios —no es la peor solución, pero ciertamente no la mejor.

En lugar de solo marcar correos que sean idénticos a correos spam conocidos, tu filtro de spam podría programarse para también marcar correos que sean muy similares a correos spam conocidos. Esto requiere una medida de similitud entre dos correos electrónicos. Una medida de similitud (muy básica) entre dos correos podría ser contar el número de palabras que tienen en común. El sistema marcaría un correo como spam si tiene muchas palabras en común con un correo spam conocido.

Esto se llama aprendizaje basado en instancias: el sistema aprende los ejemplos de memoria, y luego generaliza a nuevos casos comparándolos con los ejemplos aprendidos (o con un subconjunto de ellos), usando una medida de similitud. Por ejemplo, en la Figura 1-15, la nueva instancia sería clasificada como un triángulo porque la mayoría de las instancias más similares pertenecen a esa clase.

[[img:1.14.png]]
Figura 1-15. Aprendizaje basado en instancias
[[/img]]

### Aprendizaje basado en modelos

Otra forma de generalizar a partir de un conjunto de ejemplos es construir un modelo de estos ejemplos, y luego usar ese modelo para hacer predicciones. Esto se llama aprendizaje basado en modelos (Figura 1-16).

[[img:1.15.png]]
Figura 1-16. Aprendizaje basado en modelos
[[/img]]

Por ejemplo, supón que quieres saber si el dinero hace felices a las personas, así que descargas los datos del Índice para una Vida Mejor del sitio web de la [OCDE](https://data-explorer.oecd.org/vis?tenant=archive&df[ds]=DisseminateArchiveDMZ&df[id]=DF_BLI&df[ag]=OECD), así como estadísticas sobre el PIB per cápita del sitio web del [FMI](https://www.imf.org/external/error.htm?URL=https://www.imf.org/external/pubs/ft/weo/2016/01/weodata/weorept.aspx). Luego unes las tablas y ordenas por PIB per cápita. La Tabla 1-1 muestra un extracto de lo que obtienes.

Tabla 1-1. ¿Hace el dinero más felices a las personas?

| País | PIB per cápita (USD) | Satisfacción con la vida |
| :---- | :---- | :---- |
| Hungría | 12,240 | 4.9 |
| Corea | 27,195 | 5.8 |
| Francia | 37,675 | 6.5 |
| Australia | 50,962 | 7.3 |
| Estados Unidos | 55,805 | 7.2 |

Hagamos un gráfico de los datos para algunos países aleatorios (Figura 1-17).

[[img:1.16.png]]
Figura 1-17. ¿Ves una tendencia aquí?
[[/img]]

¡Parece que sí hay una tendencia! Aunque los datos tienen ruido (es decir, son parcialmente aleatorios), parece que la satisfacción con la vida aumenta más o menos linealmente a medida que aumenta el PIB per cápita de un país. Así que decides modelar la satisfacción con la vida como una función lineal del PIB per cápita. Este paso se llama selección de modelo: seleccionaste un modelo lineal de satisfacción con la vida con solo un atributo, el PIB per cápita (Ecuación 1-1).

Ecuación 1-1. Un modelo lineal simple

life\_satisfaction=0+1\*GDP\_per\_capita

Este modelo tiene dos parámetros de modelo, 0 y 1. Ajustando estos parámetros, puedes hacer que tu modelo represente cualquier función lineal, como se muestra en la Figura 1-18.

[[img:1.17.png]]
Figura 1-18. Algunos modelos lineales posibles
[[/img]]

Antes de poder usar tu modelo, necesitas definir los valores de los parámetros 0 y 1. ¿Cómo puedes saber qué valores harán que tu modelo funcione mejor? Para responder a esta pregunta, necesitas especificar una medida de rendimiento. Puedes definir una función de utilidad (o función de aptitud) que mida qué tan bueno es tu modelo, o puedes definir una función de costo que mida qué tan malo es. Para problemas de regresión lineal, típicamente se usa una función de costo que mide la distancia entre las predicciones del modelo lineal y los ejemplos de entrenamiento; el objetivo es minimizar esta distancia.

Aquí es donde entra el algoritmo de Regresión Lineal: le proporcionas tus ejemplos de entrenamiento y encuentra los parámetros que hacen que el modelo lineal se ajuste mejor a tus datos. Esto se llama entrenar el modelo. En nuestro caso, el algoritmo encuentra que los valores óptimos de los parámetros son 0=4.85 y 1=4.91x10-5.

Ahora el modelo se ajusta a los datos de entrenamiento lo más posible (para un modelo lineal), como puedes ver en la Figura 1-19.

[[img:1.18.png]]
Figura 1-19. El modelo lineal que mejor se ajusta a los datos de entrenamiento
[[/img]]

Ahora estás finalmente listo para ejecutar el modelo y hacer predicciones. Por ejemplo, digamos que quieres saber qué tan felices son los chipriotas, y que los datos de la OCDE no tienen la respuesta. Afortunadamente, puedes usar tu modelo para hacer una buena predicción: buscas el PIB per cápita de Chipre, encuentras $22,587, y luego aplicas tu modelo para hallar que la satisfacción con la vida probablemente esté alrededor de 4.85+22,587\*491x10-5=5.96.

Para abrir el apetito, el Ejemplo 1-1 muestra el código en Python que carga los datos, los prepara, crea un diagrama de dispersión para visualización, y luego entrena un modelo lineal y hace una predicción.

Ejemplo 1-1. Entrenar y ejecutar un modelo lineal usando Scikit-Learn

```python
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import sklearn.linear_model

# Cargar los datos
oecd_bli = pd.read_csv("oecd_bli_2015.csv", thousands=',')
gdp_per_capita = pd.read_csv("gdp_per_capita.csv", thousands=',', delimiter='\t', encoding='latin1', na_values="n/a")

# Preparar los datos
country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)
X = np.c_[country_stats["GDP per capita"]]
y = np.c_[country_stats["Life satisfaction"]]

# Visualizar los datos
country_stats.plot(kind='scatter', x="GDP per capita", y='Life satisfaction')
plt.show()

# Seleccionar un modelo lineal
model = sklearn.linear_model.LinearRegression()

# Entrenar el modelo
model.fit(X, y)

# Hacer una predicción para Chipre
X_new = [[22587]]  # PIB per cápita de Chipre
print(model.predict(X_new))  # imprime [[ 5.96242338]]
```

Si hubieras usado un algoritmo de aprendizaje basado en instancias en su lugar, habrías descubierto que Eslovenia tiene el PIB per cápita más cercano al de Chipre ($20,732), y dado que los datos de la OCDE indican que la satisfacción con la vida de los eslovenos es de 5.7, habrías predicho una satisfacción de 5.7 para Chipre. Si amplías un poco la vista y observas los dos países más cercanos, encontrarás Portugal y España con satisfacciones de 5.1 y 6.5, respectivamente. Promediando estos tres valores, obtienes 5.77, lo cual está bastante cerca de tu predicción basada en el modelo. Este algoritmo simple se llama regresión de k-Vecinos más Cercanos (en este ejemplo, k \= 3).                

Reemplazar el modelo de Regresión Lineal por la regresión de k-Vecinos más Cercanos en el código anterior es tan simple como reemplazar estas dos líneas:

```python
import sklearn.linear_model
model = sklearn.linear_model.LinearRegression()
```

por estas dos:

```python
import sklearn.neighbors
model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)
```

Si todo salió bien, tu modelo hará buenas predicciones. Si no, puede que necesites usar más atributos (tasa de empleo, salud, contaminación del aire, etc.), obtener más o mejores datos de entrenamiento, o tal vez seleccionar un modelo más potente (por ejemplo, un modelo de Regresión Polinómica).  
En resumen:

* Estudiaste los datos.  
* Seleccionaste un modelo.  
* Lo entrenaste con los datos de entrenamiento (es decir, el algoritmo de aprendizaje buscó los valores de los parámetros del modelo que minimizan una función de costo).  
* Finalmente, aplicaste el modelo para hacer predicciones sobre nuevos casos (esto se llama inferencia), esperando que este modelo generalice bien.

Así es como luce un proyecto típico de Machine Learning. En el Capítulo 2 experimentarás esto de primera mano a través de un proyecto de principio a fin.

Hemos cubierto mucho hasta ahora: ya sabes de qué trata realmente el Machine Learning, por qué es útil, cuáles son algunas de las categorías más comunes de sistemas de ML y cómo es el flujo de trabajo típico de un proyecto. Ahora veamos qué puede salir mal en el aprendizaje y evitar que hagas predicciones precisas.

# Principales desafíos del Machine Learning

En resumen, dado que tu tarea principal es seleccionar un algoritmo de aprendizaje y entrenarlo con algunos datos, las dos cosas que pueden salir mal son “mal algoritmo” y “malos datos”. Comencemos con ejemplos de malos datos.

## Cantidad insuficiente de datos de entrenamiento

Para que un niño pequeño aprenda qué es una manzana, todo lo que se necesita es que le señales una manzana y digas “manzana” (posiblemente repitiendo este procedimiento algunas veces). Ahora el niño es capaz de reconocer manzanas de todo tipo de colores y formas. Genial.

El Machine Learning aún no está en ese punto; la mayoría de los algoritmos de Machine Learning requieren muchos datos para funcionar correctamente. Incluso para problemas muy simples, normalmente se necesitan miles de ejemplos, y para problemas complejos como el reconocimiento de imágenes o de voz pueden requerirse millones de ejemplos (a menos que puedas reutilizar partes de un modelo existente).

[[card]]
## La efectividad irrazonable de los datos

En un famoso artículo publicado en 2001, los investigadores de Microsoft Michele Banko y Eric Brill demostraron que algoritmos de Machine Learning muy diferentes, incluyendo algunos bastante simples, obtenían un rendimiento casi idéntico en un problema complejo de desambiguación de lenguaje natural una vez que se les proporcionaba suficiente cantidad de datos (como se puede ver en la Figura 1-20).

[[img:1.19.png]]
Figura 1-20. La importancia de los datos frente a los algoritmos
[[/img]]

Como lo expresaron los autores: “estos resultados sugieren que quizá queramos reconsiderar la compensación entre gastar tiempo y dinero en el desarrollo de algoritmos versus gastarlo en el desarrollo de corpus”.

La idea de que los datos importan más que los algoritmos para problemas complejos fue aún más popularizada por Peter Norvig et al. en un artículo titulado “[The Unreasonable Effectiveness of Data](https://static.googleusercontent.com/media/research.google.com/es//pubs/archive/35179.pdf)” publicado en 2009\. Sin embargo, cabe señalar que los conjuntos de datos pequeños y medianos siguen siendo muy comunes, y no siempre es fácil o barato obtener datos de entrenamiento adicionales, así que no abandones los algoritmos todavía.
[[/card]]

## Datos de entrenamiento no representativos

Para generalizar bien, es crucial que tus datos de entrenamiento sean representativos de los nuevos casos a los que deseas generalizar. Esto es cierto tanto si utilizas aprendizaje basado en instancias como aprendizaje basado en modelos.

Por ejemplo, el conjunto de países que usamos antes para entrenar el modelo lineal no era perfectamente representativo; faltaban algunos países. La Figura 1-21 muestra cómo se ven los datos cuando agregas los países que faltaban.

[[img:1.20.png]]
Figura 1-21. Una muestra de entrenamiento más representativa
[[/img]]

Si entrenas un modelo lineal con estos datos, obtendrás la línea continua, mientras que el modelo anterior está representado por la línea punteada. Como puedes ver, no solo agregar unos pocos países faltantes altera significativamente el modelo, sino que deja claro que un modelo lineal tan simple probablemente nunca funcionará bien. Parece que los países muy ricos no son más felices que los países moderadamente ricos (de hecho, parecen menos felices), y, por el contrario, algunos países pobres parecen más felices que muchos países ricos.

Al usar un conjunto de entrenamiento no representativo, entrenamos un modelo que probablemente no realizará predicciones precisas, especialmente para países muy pobres y muy ricos.

Es crucial usar un conjunto de entrenamiento que sea representativo de los casos a los que deseas generalizar. Esto a menudo es más difícil de lo que parece: si la muestra es demasiado pequeña, tendrás ruido de muestreo (es decir, datos no representativos como resultado del azar), pero incluso muestras muy grandes pueden no ser representativas si el método de muestreo es defectuoso. Esto se llama sesgo de muestreo.

[[card]]
## Un Ejemplo Famoso de Sesgo de Muestreo

Quizás el ejemplo más famoso de sesgo de muestreo ocurrió durante las elecciones presidenciales de EE. UU. en 1936, que enfrentaron a Landon contra Roosevelt: la revista Literary Digest realizó una encuesta muy amplia, enviando correspondencia a unas 10 millones de personas. Recibió 2,4 millones de respuestas y predijo con gran confianza que Landon obtendría el 57 % de los votos.

En cambio, Roosevelt ganó con el 62 % de los votos. La falla estuvo en el método de muestreo de Literary Digest:

* Primero, para obtener las direcciones a las que enviar las encuestas, Literary Digest utilizó directorios telefónicos, listas de suscriptores de revistas, listas de membresías de clubes y similares. Todas estas listas tienden a favorecer a personas con mayor poder adquisitivo, que tienen más probabilidades de votar por el Partido Republicano (y por lo tanto, por Landon).  
* Segundo, menos del 25 % de las personas que recibieron la encuesta respondieron. Nuevamente, esto introduce un sesgo de muestreo, al dejar fuera a personas que no se interesan demasiado por la política, personas que no gustan de Literary Digest y otros grupos clave. Este es un tipo especial de sesgo de muestreo llamado sesgo por no respuesta.

Aquí hay otro ejemplo: supongamos que querés construir un sistema para reconocer videos de música funk. Una forma de crear tu conjunto de entrenamiento es buscar “funk music” en YouTube y usar los videos resultantes. Pero esto asume que el motor de búsqueda de YouTube devuelve un conjunto de videos que es representativo de todos los videos de música funk en YouTube. En realidad, los resultados de búsqueda probablemente estén sesgados hacia artistas populares (y si vivís en Brasil, obtendrás muchos videos de “funk carioca”, que no suenan en nada como James Brown). Por otro lado, ¿cómo más podrías obtener un conjunto de entrenamiento grande?
[[/card]]

## Datos de Mala Calidad

Obviamente, si tu conjunto de entrenamiento está lleno de errores, valores atípicos y ruido (por ejemplo, debido a mediciones de baja calidad), será más difícil para el sistema detectar los patrones subyacentes, por lo que es menos probable que tenga un buen desempeño. A menudo vale mucho la pena invertir tiempo en limpiar los datos de entrenamiento. La verdad es que la mayoría de los científicos de datos dedican una parte significativa de su tiempo a hacer justamente eso. Por ejemplo:

* Si algunas instancias son claramente valores atípicos, puede ser útil simplemente descartarlas o intentar corregir los errores manualmente.  
* Si a algunas instancias les faltan ciertos atributos (por ejemplo, el 5 % de tus clientes no especificó su edad), debés decidir si querés ignorar este atributo por completo, ignorar esas instancias, completar los valores faltantes (por ejemplo, con la edad media), o entrenar un modelo con la característica y otro sin ella, etc.

## Características Irrelevantes

Como dice el refrán: basura entra, basura sale. Tu sistema solo será capaz de aprender si el conjunto de entrenamiento contiene suficientes características relevantes y no demasiadas irrelevantes. Una parte fundamental del éxito de un proyecto de Machine Learning es idear un buen conjunto de características para entrenar. Este proceso, llamado feature engineering, implica:

* **Selección de características**: seleccionar las características más útiles para entrenar entre las ya existentes.  
* **Extracción de características**: combinar características existentes para producir una más útil (como vimos antes, los algoritmos de reducción de dimensionalidad pueden ayudar).  
* Crear nuevas características recopilando nuevos datos.

Ahora que hemos visto muchos ejemplos de datos de mala calidad, veamos un par de ejemplos de malos algoritmos.

## Sobreajuste del Conjunto de Entrenamiento

Supongamos que estás visitando un país extranjero y el taxista te estafa. Podrías sentir la tentación de decir que todos los taxistas de ese país son ladrones. La sobregeneralización es algo que los humanos hacemos con demasiada frecuencia, y desafortunadamente las máquinas pueden caer en la misma trampa si no tenemos cuidado. En Machine Learning, esto se llama overfitting: significa que el modelo funciona bien con el conjunto de entrenamiento, pero no se generaliza bien.

La Figura 1-22 muestra un ejemplo de un modelo polinómico de alto grado para la satisfacción con la vida que sobreajusta fuertemente los datos de entrenamiento. Aunque funciona mucho mejor en el conjunto de entrenamiento que el modelo lineal simple, ¿realmente confiarías en sus predicciones?

[[img:1.21.png]]
Figura 1-22. Sobreajuste de los datos de entrenamiento
[[/img]]

Los modelos complejos, como las redes neuronales profundas, pueden detectar patrones sutiles en los datos, pero si el conjunto de entrenamiento contiene ruido o si es demasiado pequeño (lo que introduce ruido de muestreo), el modelo probablemente detecte patrones en el propio ruido. Obviamente, estos patrones no se generalizarán a nuevas instancias. Por ejemplo, supongamos que le das a tu modelo de satisfacción con la vida muchos más atributos, incluidos algunos no informativos como el nombre del país. En ese caso, un modelo complejo podría detectar patrones como el hecho de que todos los países en el conjunto de entrenamiento con una w en su nombre tienen una satisfacción con la vida mayor a 7: New Zealand (7.3), Norway (7.4), Sweden (7.2), y Switzerland (7.5). ¿Qué tan seguro estás de que la regla de la W-satisfacción se generaliza a Ruanda o Zimbabue? Obviamente, este patrón ocurrió en los datos de entrenamiento por pura casualidad, pero el modelo no tiene forma de saber si un patrón es real o simplemente el resultado del ruido en los datos.

> El overfitting ocurre cuando el modelo es demasiado complejo en relación con la cantidad y el nivel de ruido del conjunto de entrenamiento. Las posibles soluciones son:

* Simplificar el modelo seleccionando uno con menos parámetros (por ejemplo, un modelo lineal en lugar de uno polinómico de alto grado), reduciendo el número de atributos en el conjunto de entrenamiento o restringiendo el modelo.  
* Obtener más datos de entrenamiento.  
* Reducir el ruido en el conjunto de entrenamiento (por ejemplo, corrigiendo errores de datos y eliminando valores atípicos).

Restringir un modelo para hacerlo más simple y reducir el riesgo de overfitting se llama regularización. Por ejemplo, el modelo lineal que definimos antes tiene dos parámetros, 0 y 1\. Esto le da al algoritmo de aprendizaje dos grados de libertad para ajustar el modelo a los datos de entrenamiento: puede modificar tanto la altura (0) como la pendiente (1) de la línea. Si forzamos 1=0, el algoritmo tendría solo un grado de libertad y le sería mucho más difícil ajustar correctamente los datos: todo lo que podría hacer es mover la línea hacia arriba o hacia abajo para acercarse lo más posible a las instancias de entrenamiento, terminando alrededor de la media. ¡Un modelo muy simple, de hecho\! Si permitimos que el algoritmo modifique 1 pero le imponemos que lo mantenga pequeño, entonces el algoritmo de aprendizaje tendrá, en la práctica, algo entre uno y dos grados de libertad. Producirá un modelo más simple que con dos grados de libertad, pero más complejo que con solo uno. Querés encontrar el equilibrio correcto entre ajustar perfectamente los datos de entrenamiento y mantener el modelo lo suficientemente simple para asegurar que se generalice bien.

La Figura 1-23 muestra tres modelos: la línea punteada representa el modelo original que se entrenó con algunos países faltantes, la línea discontinua es nuestro segundo modelo entrenado con todos los países, y la línea continua es un modelo lineal entrenado con los mismos datos que el primer modelo pero con una restricción de regularización. Podés ver que la regularización obligó al modelo a tener una pendiente más pequeña, lo que ajusta un poco menos los datos de entrenamiento, pero en realidad le permite generalizar mejor a nuevos ejemplos.

[[img:1.22.png]]
Figura 1-23. La regularización reduce el riesgo de sobreajuste
[[/img]]

La cantidad de regularización a aplicar durante el aprendizaje puede controlarse mediante un hiperparámetro. Un hiperparámetro es un parámetro de un algoritmo de aprendizaje (no del modelo). Por lo tanto, no se ve afectado por el propio algoritmo de aprendizaje; debe establecerse antes del entrenamiento y permanece constante durante este. Si establecés el hiperparámetro de regularización en un valor muy grande, obtendrás un modelo casi plano (una pendiente cercana a cero); el algoritmo de aprendizaje casi con seguridad no sobreajustará los datos de entrenamiento, pero será menos probable que encuentre una buena solución. Ajustar hiperparámetros es una parte importante de la construcción de un sistema de Machine Learning (verás un ejemplo detallado en el próximo capítulo).

## Subajuste del Conjunto de Entrenamiento

Como habrás adivinado, el underfitting es lo opuesto al overfitting: ocurre cuando tu modelo es demasiado simple para aprender la estructura subyacente de los datos. Por ejemplo, un modelo lineal de satisfacción con la vida es propenso a subajustar; la realidad es simplemente más compleja que el modelo, por lo que sus predicciones inevitablemente serán inexactas, incluso en los ejemplos de entrenamiento.

Las principales opciones para resolver este problema son:

* Seleccionar un modelo más potente, con más parámetros.  
* Proporcionar mejores características al algoritmo de aprendizaje (feature engineering).  
* Reducir las restricciones del modelo (por ejemplo, reduciendo el hiperparámetro de regularización).

## Tomando Perspectiva

A esta altura ya sabés bastante sobre Machine Learning. Sin embargo, hemos pasado por tantos conceptos que puede que te sientas un poco perdido, así que tomemos perspectiva y veamos el panorama general:

* El Machine Learning trata de lograr que las máquinas mejoren en una tarea aprendiendo a partir de datos, en lugar de tener que programar reglas explícitamente.  
* Hay muchos tipos diferentes de sistemas de ML: supervisados o no, batch u online, basados en instancias o en modelos, etc.  
* En un proyecto de ML reunís datos en un conjunto de entrenamiento y se los das a un algoritmo de aprendizaje. Si el algoritmo está basado en modelos, ajusta algunos parámetros para adaptar el modelo al conjunto de entrenamiento (es decir, para hacer buenas predicciones en el propio conjunto de entrenamiento) y luego, con suerte, también podrá hacer buenas predicciones sobre nuevos casos. Si el algoritmo está basado en instancias, simplemente aprende los ejemplos de memoria y generaliza a nuevas instancias comparándolas con las aprendidas usando una medida de similitud.  
* El sistema no tendrá un buen rendimiento si tu conjunto de entrenamiento es demasiado pequeño o si los datos no son representativos, contienen ruido o están contaminados con características irrelevantes (basura entra, basura sale). Por último, tu modelo no debe ser ni demasiado simple (en cuyo caso subajustará) ni demasiado complejo (en cuyo caso sobreajustará).

Solo queda un último tema importante por cubrir: una vez que entrenaste un modelo, no querés simplemente “esperar” que se generalice a nuevos casos. Querés evaluarlo y ajustarlo si es necesario. Veamos cómo.

# Pruebas y validación

La única manera de saber qué tan bien se generalizará un modelo a nuevos casos es, de hecho, probarlo en casos nuevos. Una forma de hacerlo es poner tu modelo en producción y monitorear qué tan bien se desempeña. Esto funciona bien, pero si tu modelo es terriblemente malo, tus usuarios se quejarán —no es la mejor idea.

Una mejor opción es dividir tus datos en dos conjuntos: el training set y el test set. Como sus nombres lo indican, entrenás tu modelo usando el training set y lo probás usando el test set. La tasa de error en casos nuevos se llama generalization error (o out-of-sample error), y al evaluar tu modelo en el test set, obtenés una estimación de este error. Este valor te dice qué tan bien se desempeñará tu modelo en instancias que nunca ha visto antes.

Si el training error es bajo (es decir, tu modelo comete pocos errores en el training set), pero el generalization error es alto, significa que tu modelo está overfitting los datos de entrenamiento.

> Es común usar el 80% de los datos para entrenamiento y reservar el 20% para pruebas. Sin embargo, esto depende del tamaño del dataset: si contiene 10 millones de instancias, entonces reservar el 1% significa que tu test set contendrá 100,000 instancias: probablemente sea más que suficiente para obtener una buena estimación del generalization error.

## Ajuste de hiperparámetros y selección de modelo

Entonces, evaluar un modelo es bastante sencillo: simplemente usá un test set. Ahora supongamos que estás dudando entre dos modelos (digamos, un modelo lineal y un modelo polinómico): ¿cómo podés decidir? Una opción es entrenar ambos y comparar qué tan bien se generalizan usando el test set.

Ahora supongamos que el modelo lineal se generaliza mejor, pero querés aplicar algo de regularización para evitar el overfitting. La pregunta es: ¿cómo elegís el valor del hiperparámetro de regularización? Una opción es entrenar 100 modelos diferentes usando 100 valores distintos para este hiperparámetro. Supongamos que encontrás el valor de hiperparámetro que produce un modelo con el menor generalization error, digamos, solo un 5% de error. 

Entonces lanzás este modelo a producción, pero desafortunadamente no se desempeña tan bien como esperabas y produce un 15% de errores. ¿Qué pasó?

El problema es que mediste el generalization error varias veces en el test set, y adaptaste el modelo y los hiperparámetros para producir el mejor modelo para ese conjunto en particular. Esto significa que es poco probable que el modelo se desempeñe igual de bien en nuevos datos.

Una solución común a este problema se llama holdout validation: simplemente reservás parte del training set para evaluar varios modelos candidatos y seleccionar el mejor. El nuevo conjunto reservado se llama validation set (o a veces development set o dev set). Más específicamente, entrenás múltiples modelos con varios hiperparámetros en el training set reducido (es decir, el training set completo menos el validation set), y seleccionás el modelo que mejor se desempeñe en el validation set. Después de este proceso de holdout validation, entrenás el mejor modelo en el training set completo (incluyendo el validation set), y esto te da el modelo final. Por último, evaluás este modelo final en el test set para obtener una estimación del generalization error.

Esta solución generalmente funciona bastante bien. Sin embargo, si el validation set es demasiado pequeño, entonces las evaluaciones de los modelos serán imprecisas: podrías terminar seleccionando un modelo subóptimo por error. Por el contrario, si el validation set es demasiado grande, entonces el training set restante será mucho más pequeño que el training set completo. ¿Por qué es esto malo? Bueno, dado que el modelo final se entrenará en el training set completo, no es ideal comparar modelos candidatos entrenados en un conjunto de entrenamiento mucho más pequeño. Sería como seleccionar al velocista más rápido para participar en una maratón. Una forma de resolver este problema es realizar repeated cross-validation, usando muchos conjuntos pequeños de validación. Cada modelo se evalúa una vez por cada validation set, después de ser entrenado con el resto de los datos. Al promediar todas las evaluaciones de un modelo, obtenemos una medida mucho más precisa de su rendimiento. Sin embargo, hay una desventaja: el tiempo de entrenamiento se multiplica por el número de validation sets.

## Desajuste de datos

En algunos casos, es fácil obtener una gran cantidad de datos para entrenamiento, pero no son perfectamente representativos de los datos que se usarán en producción. Por ejemplo, supongamos que querés crear una aplicación móvil para tomar fotos de flores y determinar automáticamente su especie. Podés descargar fácilmente millones de fotos de flores en la web, pero no serán perfectamente representativas de las fotos que realmente se tomarán usando la aplicación en un dispositivo móvil. Quizás solo tengas 10,000 fotos representativas (es decir, realmente tomadas con la aplicación). En este caso, la regla más importante a recordar es que el validation set y el test set deben ser lo más representativos posible de los datos que esperás usar en producción, por lo que deben componerse exclusivamente de fotos representativas: podés barajarlas y poner la mitad en el validation set y la otra mitad en el test set (asegurándote de que no haya duplicados ni casi duplicados en ambos conjuntos).  
Después de entrenar tu modelo con las fotos de la web, si observás que el rendimiento de tu modelo en el validation set es decepcionante, no sabrás si esto se debe a que tu modelo hizo overfitting al training set, o si simplemente se debe al desajuste entre las fotos de la web y las fotos de la aplicación móvil. Una solución es reservar parte de las fotos de entrenamiento (de la web) en otro conjunto que Andrew Ng llama el train-dev set. Después de que el modelo se entrena (en el training set, no en el train-dev set), podés evaluarlo en el train-dev set: si se desempeña bien, entonces el modelo no está haciendo overfitting al training set, por lo que si se desempeña mal en el validation set, el problema debe provenir del desajuste de datos. Podés intentar abordar este problema preprocesando las imágenes de la web para que se parezcan más a las fotos que tomará la aplicación móvil, y luego volver a entrenar el modelo. Por el contrario, si el modelo se desempeña mal en el train-dev set, entonces el modelo debe haber hecho overfitting al training set, por lo que deberías intentar simplificar o regularizar el modelo, obtener más datos de entrenamiento y limpiar los datos de entrenamiento, como se discutió antes.

[card]
## Teorema de No Free Lunch

Un modelo es una versión simplificada de las observaciones. Las simplificaciones están pensadas para descartar los detalles superfluos que probablemente no se generalicen a nuevas instancias. Sin embargo, para decidir qué datos descartar y cuáles conservar, debés hacer suposiciones. Por ejemplo, un modelo lineal asume que los datos son fundamentalmente lineales y que la distancia entre las instancias y la línea recta es solo ruido, que se puede ignorar sin problemas.

En un famoso artículo de 1996, David Wolpert demostró que si no hacés absolutamente ninguna suposición sobre los datos, entonces no hay razón para preferir un modelo sobre otro. Esto se llama el teorema de No Free Lunch (NFL). Para algunos datasets, el mejor modelo es uno lineal, mientras que para otros es una red neuronal. No hay un modelo que esté garantizado a priori para funcionar mejor (de ahí el nombre del teorema). La única manera de saber con certeza cuál es el mejor modelo es evaluarlos todos. Como esto no es posible, en la práctica hacés algunas suposiciones razonables sobre los datos y evaluás solo unos pocos modelos razonables. Por ejemplo, para tareas simples podés evaluar modelos lineales con varios niveles de regularización, y para un problema complejo podés evaluar varias redes neuronales.
[/card]

# Ejercicios

En este capítulo hemos cubierto algunos de los conceptos más importantes en Machine Learning. En los próximos capítulos profundizaremos y escribiremos más código, pero antes de hacerlo, asegurate de saber cómo responder las siguientes preguntas:

1. ¿Cómo definirías Machine Learning?  
2. ¿Podés nombrar cuatro tipos de problemas en los que destaque?  
3. ¿Qué es un labeled training set?  
4. ¿Cuáles son las dos tareas supervisadas más comunes?  
5. ¿Podés nombrar cuatro tareas no supervisadas comunes?  
6. ¿Qué tipo de algoritmo de Machine Learning usarías para permitir que un robot camine en diversos terrenos desconocidos?  
7. ¿Qué tipo de algoritmo usarías para segmentar a tus clientes en varios grupos?  
8. ¿Plantearías el problema de detección de spam como un problema de supervised learning o de unsupervised learning?  
9. ¿Qué es un sistema de online learning?  
10. ¿Qué es out-of-core learning?  
11. ¿Qué tipo de algoritmo de aprendizaje se basa en una medida de similitud para hacer predicciones?  
12. ¿Cuál es la diferencia entre un parámetro de modelo y un hiperparámetro de un algoritmo de aprendizaje?  
13. ¿Qué buscan los algoritmos de aprendizaje basados en modelos? ¿Cuál es la estrategia más común que usan para tener éxito? ¿Cómo hacen predicciones?  
14. ¿Podés nombrar cuatro de los principales desafíos en Machine Learning?  
15. Si tu modelo funciona muy bien con los datos de entrenamiento pero se generaliza mal a nuevas instancias, ¿qué está pasando? ¿Podés nombrar tres posibles soluciones?  
16. ¿Qué es un test set y por qué querrías usarlo?  
17. ¿Cuál es el propósito de un validation set?  
18. ¿Qué puede salir mal si ajustás los hiperparámetros usando el test set?  
19. ¿Qué es repeated cross-validation y por qué la preferirías a usar un solo validation set?